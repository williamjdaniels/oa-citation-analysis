# Open Access Citation Advantage Analysis

[![R](https://img.shields.io/badge/R-%3E%3D4.0-blue.svg)](https://www.r-project.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A reproducible analysis pipeline examining the relationship between Open Access publishing types and citation counts in academic ophthalmology literature.

---

## Overview

This project investigates whether Open Access (OA) publishing confers a citation advantage compared to traditional closed access publishing. Using inverse probability of treatment weighting (IPTW) with entropy balancing and weighted negative binomial mixed-effects models, we rigorously estimate the causal effect of OA status on citation counts while controlling for confounding variables.

### Key Features

- **Causal inference framework**: Entropy balancing weights to address selection bias
- **Appropriate count modeling**: Negative binomial distribution for overdispersed citation data
- **Hierarchical structure**: Random slopes account for journal-level variation
- **Comprehensive diagnostics**: Model comparison, overdispersion tests, and balance checks
- **Publication-ready outputs**: Figures and tables formatted for manuscript submission

---

## Methods

### Study Design

Articles are stratified into four Open Access categories:

| OA Type | Description |
|---------|-------------|
| **Gold** | Published in fully OA journals or as OA in hybrid journals |
| **Green** | Self-archived version available in a repository |
| **Bronze** | Freely readable on publisher site without explicit license |
| **Closed** | No free access available |

### Statistical Approach

```
Citation Count ~ OA Type + Author Count + AIS + Publication Year + Document Type
                + OA Type × Year + (Year | Journal)
```

**Weighting**: Entropy balancing (`method = "ebal"`) generates weights that exactly balance covariate means across OA groups, reducing confounding bias.

**Model**: Weighted negative binomial GLMM fitted with `glmmTMB`, accounting for overdispersion and journal-level clustering with random slopes for publication year trends.

---

## Repository Structure

```
├── main.sh                        # Shell script to run the full pipeline
├── 01_data_prep.R                 # Data loading, cleaning, and scaling
├── 02_analysis.R                  # Modeling, diagnostics, figures, and tables
├── README.md
│
├── Data (user-supplied)
│   ├── All Journals and Articles with Stratified OA.xlsx - Sheet1.csv
│   └── AIS2023_dat - Sheet1.csv
│
├── Intermediate outputs (generated by 01_data_prep.R)
│   ├── min_data.csv               # Processed dataset
│   └── scaling_params.csv         # Z-standardization parameters
│
├── Model objects
│   ├── final_weighted_model.rds   # Pre-fitted model (loaded by 02_analysis.R)
│   └── citation_model.rds         # Model re-saved by 02_analysis.R
│
├── Figures (generated by 02_analysis.R)
│   ├── Love_plot.tiff             # Covariate balance visualization
│   ├── Access Type by Citations.tiff  # Boxplot of citations by OA type
│   ├── YearPlot.png               # OA × Publication Year interaction
│   ├── AuthorPlot.tiff            # Author count effects by OA type
│   └── citation_analysis_supplementary.tiff  # Pairwise comparison forest plot
│
└── Tables (generated by 02_analysis.R)
    ├── Table1_Descriptive_Statistics.csv
    ├── Table2_Model_Estimates_IRR.csv
    ├── Table3_Pairwise_Comparisons.csv
    ├── Supplement_Weighting_Balance.csv
    ├── Model_Diagnostics_Summary.csv
    ├── anova_results.csv
    ├── anova_table.docx
    └── processed_citation_data.csv  # Final dataset (Authors column removed)
```

---

## Installation

### Prerequisites

R version ≥ 4.0 with the following packages:

```r
# Core modeling
install.packages(c("glmmTMB", "lme4", "lmerTest", "emmeans", "MASS", "lmtest"))

# Causal inference
install.packages(c("WeightIt", "cobalt"))

# Visualization
install.packages(c("ggplot2", "ggpubr", "patchwork", "scales", "splines"))

# Tables & export
install.packages(c("flextable", "xtable", "stargazer", "knitr"))

# Utilities
install.packages(c("tidyverse", "vroom", "data.table", "broom", "broom.mixed"))

# Diagnostics
install.packages(c("DHARMa", "performance", "MuMIn", "car"))
```

### Data Requirements

Place these input files in the project root directory:

1. **`All Journals and Articles with Stratified OA.xlsx - Sheet1.csv`** — Main article dataset containing journal title, publication year, OA status, citation counts, authors, and document type
2. **`AIS2023_dat - Sheet1.csv`** — Journal Article Influence Scores (AIS)
3. **`final_weighted_model.rds`** — Pre-fitted weighted negative binomial GLMM object (loaded by `02_analysis.R`)

> **Note**: The AIS data path in `01_data_prep.R` defaults to `~/Downloads/AUCompBio-OA_2021_AU-cd94c12/AIS2023_dat - Sheet1.csv`. Update this path to match your local file location.

---

## Usage

### Run the full pipeline

```bash
bash main.sh
```

This executes both scripts in sequence:

1. **`01_data_prep.R`** — Loads raw CSV files, recodes Hybrid as Gold, filters years (removes 2020–2022) and rare document types, calculates author counts, merges AIS scores, Z-standardizes continuous variables, and exports `min_data.csv` and `scaling_params.csv`.

2. **`02_analysis.R`** — Loads the processed data and pre-fitted model, generates entropy balancing weights, runs model diagnostics (overdispersion, R², Poisson vs. NB comparison, NB vs. ZINB comparison), produces all figures and tables, and exports results for manuscript submission.

### Run scripts individually

```r
# Step 1: Data preparation
Rscript 01_data_prep.R

# Step 2: Analysis and visualization
Rscript 02_analysis.R
```

---

## Pipeline Details

### Script 1: Data Preparation (`01_data_prep.R`)

| Step | Description |
|------|-------------|
| Load data | Reads article and AIS datasets via `vroom` |
| Recode OA | Merges "Hybrid" into "Gold" category |
| Filter years | Removes 2020–2022 (incomplete citation windows) |
| Filter document types | Retains the 6 most common document types |
| Author counts | Counts commas in author field + 1 |
| Merge AIS | Left-joins Article Influence Scores by journal |
| Scale variables | Z-standardizes author count, AIS, and publication year |
| Factor encoding | Sets OA levels as Bronze (ref), Closed Access, Green, Gold |
| Export | Saves `min_data.csv` and `scaling_params.csv` |

### Script 2: Analysis (`02_analysis.R`)

| Step | Description |
|------|-------------|
| Descriptive statistics | Summary by OA type (mean, median, SD, IQR, zero-citation %) |
| Entropy balancing | IPTW weights via `WeightIt` with `method = "ebal"` |
| Balance diagnostics | Love plot and standardized mean differences |
| Model loading | Reads pre-fitted `final_weighted_model.rds` |
| Model comparisons | Poisson vs. NB; NB vs. ZINB (likelihood ratio tests) |
| Diagnostics | Overdispersion test, marginal/conditional R² |
| Figure 1 | Boxplot of citations by OA type (log scale) |
| Figure 2 | OA × Year interaction, faceted by document type |
| Figure 3 | Author count × OA type, faceted by document type |
| Supplementary figure | Forest plot of pairwise comparisons |
| ANOVA table | Type II Wald χ² tests (exported as CSV, LaTeX, and DOCX) |
| Manuscript tables | Descriptive stats, IRR estimates, pairwise comparisons, balance, diagnostics |

---

## Key Outputs

### Model Results

The primary model estimates Incidence Rate Ratios (IRRs) comparing citation rates across OA types:

- **IRR > 1**: Higher citation rate compared to reference category
- **IRR < 1**: Lower citation rate compared to reference category

### Figures

| Figure | File | Description |
|--------|------|-------------|
| Love Plot | `Love_plot.tiff` | Covariate balance before/after weighting |
| Boxplot | `Access Type by Citations.tiff` | Citation distributions by OA type |
| Year Plot | `YearPlot.png` | OA × Publication Year interaction effects |
| Author Plot | `AuthorPlot.tiff` | Citation rates by author count and OA type |
| Forest Plot | `citation_analysis_supplementary.tiff` | Pairwise comparisons with 95% CIs |

### Tables

| Table | File | Description |
|-------|------|-------------|
| Table 1 | `Table1_Descriptive_Statistics.csv` | Summary statistics by OA type |
| Table 2 | `Table2_Model_Estimates_IRR.csv` | Fixed-effect IRRs with 95% CIs |
| Table 3 | `Table3_Pairwise_Comparisons.csv` | Tukey-adjusted pairwise comparisons |
| ANOVA | `anova_table.docx` / `anova_results.csv` | Type II Wald χ² tests |
| Balance | `Supplement_Weighting_Balance.csv` | Standardized mean differences |
| Diagnostics | `Model_Diagnostics_Summary.csv` | R², overdispersion ratio and p-value |

---

## Model Specification

### Fixed Effects

| Variable | Description | Scaling |
|----------|-------------|---------|
| `Open Access Stratified` | 4-level factor (Bronze, Closed, Gold, Green) | Reference: Bronze |
| `auth_count_scaled` | Number of authors | Z-standardized |
| `AIS_scaled` | Article Influence Score | Z-standardized |
| `pub_year_scaled` | Publication year | Z-standardized |
| `Document Type` | Article, Review, Letter, etc. | Categorical |

### Random Effects

- Random intercept for `Journal Title`
- Random slope for `pub_year_scaled` by journal (captures heterogeneous citation trends)

### Interaction

- `pub_year_scaled × Open Access Stratified`: Tests whether OA effects change over time

---

## Reproducibility

```r
# The pipeline saves all intermediate and final outputs:
# From 01_data_prep.R:
#   min_data.csv, scaling_params.csv

# From 02_analysis.R:
#   citation_model.rds, processed_citation_data.csv
#   All figures and tables listed above

# To reload:
model <- readRDS("citation_model.rds")
data  <- read.csv("processed_citation_data.csv")
```

---

## Citation

If you use this code in your research, please cite:

```bibtex
@software{oa_citation_analysis,
  author = {[William Daniels]},
  title = {Open Access Citation Advantage Analysis},
  year = {2024},
  url = {https://github.com/williamjdaniels/oa-citation-analysis}
}
```

---

## License

This project is licensed under the MIT License — see [LICENSE](LICENSE) for details.

---

## Acknowledgments

- [WeightIt](https://ngreifer.github.io/WeightIt/) for propensity score weighting
- [glmmTMB](https://glmmtmb.github.io/glmmTMB/) for generalized linear mixed models
- [cobalt](https://ngreifer.github.io/cobalt/) for balance assessment and Love plots

---

## Contact

For questions or collaboration inquiries, please open an issue or contact williamjdaniels116@gmail.com